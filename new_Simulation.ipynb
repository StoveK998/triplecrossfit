{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import statsmodels.formula.api as smf\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from mlxtend.classifier import StackingCVClassifier,StackingClassifier\n",
    "from mlxtend.regressor import StackingCVRegressor,StackingRegressor\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from pygam import GAM,LogisticGAM\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from scipy.special import expit\n",
    "xgb.set_config(verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Simulation3, we introduced some slices of MRI image, and here are the libraries needed.\n",
    "from nilearn import image\n",
    "from nilearn.masking import apply_mask\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import Symbol, exp, log\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.stats\n",
    "import numpy.random as nrd\n",
    "import multiprocessing\n",
    "# In Simulation3, we no more need the function \"HDFPCA\" to create image, so here is the image generator.\n",
    "def gene_image(SampleNumber):\n",
    "    w_masked_path = './triple-crossfitting/waiting_mask/'\n",
    "    filename_lst = [w_masked_path+i for i in os.listdir(w_masked_path)]\n",
    "    intersect = nib.load(\"./triple-crossfitting/cc_masks0/intersect.nii.gz\")\n",
    "    image_array = []\n",
    "    i=0\n",
    "    # Randomly selected slices\n",
    "    for _ in range(SampleNumber):\n",
    "        file_num = random.randrange(400, 700)\n",
    "        row_num = random.randrange(5, 60)\n",
    "        index_num = random.randrange(5, 60)\n",
    "        high_num = random.randrange(5, 84)\n",
    "        start_num1 = random.randrange(1, 15)\n",
    "        start_num2 = random.randrange(1, 30)\n",
    "        row_img = nib.load(filename_lst[file_num])\n",
    "        int_img = row_img.get_fdata()\n",
    "        random_num = random.choice([0,1,2]) # Randomly selected axial slices\n",
    "        if random_num==0:\n",
    "            new_img = int_img[row_num,start_num1:start_num1+50,start_num2:start_num2+50]\n",
    "        elif random_num==1:\n",
    "            new_img = int_img[start_num1:start_num1+50,index_num,start_num2:start_num2+50]\n",
    "        elif random_num==2:\n",
    "            new_img = int_img[start_num1:start_num1+50,start_num1:start_num1+50,high_num]\n",
    "        new_img = new_img/1000\n",
    "        np.save('./triple-crossfitting/simu_img/'+str(i)+'.npy',new_img)\n",
    "        image_array.append(new_img)\n",
    "        i+=1\n",
    "    return np.array(image_array)\n",
    "\n",
    "# L = 10\n",
    "# pg = 250\n",
    "def get_X_bar(X,N): # x = observers\n",
    "    X_bar = X.reshape((N, -1))/50   # transfer x to vector ( N * grid)\n",
    "    X_bar = X_bar - np.mean(X_bar, 0)[np.newaxis]   # centered x\n",
    "    return X_bar \n",
    "\n",
    "def get_est_U(X,N,return_eigenscore=False):\n",
    "    # SVD过程\n",
    "    X_bar = X.reshape((N, -1))/50   # transfer x to vector ( N * grid)\n",
    "    X_bar = X_bar - np.mean(X_bar, 0)[np.newaxis]   # centered x\n",
    "    X_bar_square = np.zeros(shape=[N, N])\n",
    "    for l in range(10):\n",
    "        X_bar_part = X_bar[:, l*250:(l+1)*250]\n",
    "        X_bar_square += np.matmul(X_bar_part, X_bar_part.transpose())\n",
    "\n",
    "    v, s_2, vt = la.svd(X_bar_square)  # u: n*n, s: n (eigenvalue)\n",
    "    est_eimg = np.zeros([N, 10, 250])\n",
    "    for l in range(10):\n",
    "        X_bar_part = X_bar[:, l*250:(l+1)*250]\n",
    "        est_eimg[:, l] = np.matmul(X_bar_part.T, np.matmul(v, np.sqrt(np.diag(1/s_2)))).T # U(m)=X(m)VS_-1\n",
    "    U = est_eimg.reshape((N, -1))\n",
    "    if return_eigenscore==False:\n",
    "        return U.T\n",
    "    else:\n",
    "        return np.matmul(U,X_bar.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setting\n",
    "LG_psmodel = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "Linear_rspmodel = LinearRegression()\n",
    "\n",
    "RF_psmodel = RandomForestClassifier()\n",
    "RF_rspmodel = RandomForestRegressor()\n",
    "\n",
    "ADA_rspmodel = AdaBoostRegressor(learning_rate=0.05)\n",
    "ADA_psmodel = AdaBoostClassifier()\n",
    "\n",
    "XGB_rspmodel = xgb.XGBRegressor(n_estimators=500,learning_rate=0.005)\n",
    "XGB_psmodel = xgb.XGBClassifier(n_estimators=500,learning_rate=0.005)\n",
    "\n",
    "GAM_rspmodel = GAM(link='identity',n_splines=4,lam=0.6,max_iter=10000)\n",
    "GAM_psmodel =  LogisticGAM(n_splines=4,lam=0.6,max_iter=10000)\n",
    "\n",
    "BPNN_rspmodel = MLPRegressor(hidden_layer_sizes=(128,),activation='relu',max_iter=100,solver='lbfgs')\n",
    "BPNN_psmodel = MLPClassifier(hidden_layer_sizes=(128,),activation='relu',max_iter=100,solver='lbfgs')\n",
    "\n",
    "ps_mds = [LG_psmodel,RF_psmodel,ADA_psmodel,XGB_psmodel,BPNN_psmodel]\n",
    "rsp_mds = [Linear_rspmodel,RF_rspmodel,ADA_rspmodel,GAM_rspmodel]\n",
    "\n",
    "import DRModel\n",
    "dr = DRModel()\n",
    "dr.ml_models(binary_models=ps_mds,continue_models=rsp_mds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other functions\n",
    "def flatten(lis):\n",
    "    ret=[]\n",
    "    for item in lis:\n",
    "        if not isinstance(item,list):\n",
    "            ret.append(item)\n",
    "        else:\n",
    "            ret.extend(flatten(item))\n",
    "    return ret\n",
    "def coverage(p,lower,upper,true_value):\n",
    "    pp=len(p)\n",
    "    count = 0.0\n",
    "    for _ in range(pp):\n",
    "        if true_value[_] >= lower[_] and true_value[_] <= upper[_]:\n",
    "            count+=1.0\n",
    "    return count/pp\n",
    "\n",
    "def I(val_lst,min_thred=-100000,max_thred=100000):\n",
    "    kk = []\n",
    "    for val in val_lst:\n",
    "        if val>=min_thred and val<=max_thred:\n",
    "            kk.append(1)\n",
    "        else:\n",
    "            kk.append(0)\n",
    "    return np.array(kk)\n",
    "\n",
    "def sample_splitting(dataframe,png,ids,resample=False,sample_num=800):\n",
    "#     simu_frame_s1 = dataframe[dataframe['par']==ids] # shuffle\n",
    "    simu_frame_s1 = dataframe\n",
    "    observers_s1 = png[simu_frame_s1.index]\n",
    "    if resample==True:\n",
    "        simu_frame_s = simu_frame_s1.sample(frac=1)\n",
    "        observers_s = png[simu_frame_s.index]\n",
    "    else:\n",
    "        simu_frame_s = simu_frame_s1\n",
    "        observers_s = observers_s1  \n",
    "    true_ate1 = (simu_frame_s[simu_frame_s['Treatment']==1]['Y'].mean() - simu_frame_s[simu_frame_s['Treatment']==0]['Y'].mean())\n",
    "    frame_length = len(simu_frame_s.index)\n",
    "    simu_frame1 = simu_frame_s.iloc[:int(frame_length*0.25),:]\n",
    "    image_observer1 = observers_s[:int(frame_length*0.25),:] #图像切分\n",
    "    \n",
    "    simu_frame2 = simu_frame_s.iloc[int(frame_length*0.25):int(frame_length*0.5),:]\n",
    "    image_observer2 = observers_s[int(frame_length*0.25):int(frame_length*0.5),:] #图像切分\n",
    "    \n",
    "    simu_frame3 = simu_frame_s.iloc[int(frame_length*0.5):int(frame_length*0.75),:]\n",
    "    image_observer3 = observers_s[int(frame_length*0.5):int(frame_length*0.75),:] #图像切分\n",
    "    \n",
    "    simu_frame4 = simu_frame_s.iloc[int(frame_length*0.75):,:]\n",
    "    image_observer4 = observers_s[int(frame_length*0.75):,:] #图像切分\n",
    "    \n",
    "    return true_ate1,simu_frame1,image_observer1,simu_frame2,image_observer2,simu_frame3,image_observer3,simu_frame4,image_observer4   \n",
    "     \n",
    "def dc_sample_splitting(simu_frame_s): \n",
    "    frame_length = len(simu_frame_s.index)\n",
    "    simu_frame1 = simu_frame_s.iloc[:int(frame_length*0.333333),:]\n",
    "    simu_frame2 = simu_frame_s.iloc[int(frame_length*0.333333):int(frame_length*0.666666),:]\n",
    "    simu_frame3 = simu_frame_s.iloc[int(frame_length*0.666666):,:]\n",
    "    \n",
    "    return simu_frame1,simu_frame2,simu_frame3  \n",
    "    \n",
    "def frame_reindex(frame):\n",
    "    a = pd.DataFrame(frame,columns = ['egs'])\n",
    "    a['idx'] = ['es'+str(i) for i in range(len(a))]\n",
    "    a = a.set_index('idx')\n",
    "    return pd.Series(a['egs'])\n",
    "\n",
    "def getate(some_ate,tate,par):\n",
    "    b_ate_hat = {}\n",
    "#     some_ate = baseline_ate\n",
    "    b_indicators = list(some_ate.keys())\n",
    "    sec_keys = ['True','Main Effect','ML']\n",
    "    for indi in some_ate:\n",
    "        b_ate_hat[indi] = {}\n",
    "        for sec_key in sec_keys:\n",
    "            b_ate_hat[indi][sec_key] = []\n",
    "            ate_p = []\n",
    "            sd_p = []\n",
    "            upper_ci_p = []\n",
    "            lower_ci_p = []\n",
    "            for i in partition:\n",
    "                sps_p = []\n",
    "                sps_var = []\n",
    "                par_ate = np.mean(some_ate[indi][sec_key][i],axis=0)\n",
    "                for sps in range(par):\n",
    "                    sp_p = some_ate[indi][sec_key][i][sps]\n",
    "                    sps_p.append(np.mean(sp_p))\n",
    "                    sps_var.append(np.var(sp_p - par_ate[:len(sp_p)], ddof=1)/len(sp_p))\n",
    "                single_ate = np.mean(sps_p)\n",
    "                single_sd = np.sqrt(np.median(sps_var + (sps_p - single_ate)**2))\n",
    "                ate_p.append(single_ate)\n",
    "                sd_p.append(single_sd)\n",
    "                upper_ci_p.append(single_ate+1.96*single_sd)\n",
    "                lower_ci_p.append(single_ate-1.96*single_sd)\n",
    "            for aa in range(len(ate_p)):\n",
    "                b_ate_hat[indi][sec_key].append((ate_p[aa],tate[aa]))\n",
    "    return b_ate_hat\n",
    "\n",
    "def evaluate(some_ate,tate,par):\n",
    "    b_indicators = list(some_ate.keys())\n",
    "    sec_keys = ['True','Main Effect','ML']\n",
    "    for indi in some_ate:\n",
    "        for sec_key in sec_keys:\n",
    "            ate_p = []\n",
    "            sd_p = []\n",
    "            upper_ci_p = []\n",
    "            lower_ci_p = []\n",
    "            for i in partition:\n",
    "                sps_p = []\n",
    "                sps_var = []\n",
    "                par_ate = np.mean(some_ate[indi][sec_key][i],axis=0)\n",
    "                for sps in range(par):\n",
    "                    sp_p = some_ate[indi][sec_key][i][sps]\n",
    "                    sps_p.append(np.mean(sp_p))\n",
    "                    sps_var.append(np.var(sp_p - par_ate[:len(sp_p)], ddof=1)/len(sp_p))\n",
    "                single_ate = np.mean(sps_p)\n",
    "                single_sd = np.sqrt(np.median(sps_var + (sps_p - single_ate)**2))\n",
    "                ate_p.append(single_ate)\n",
    "                sd_p.append(single_sd)\n",
    "                upper_ci_p.append(single_ate+1.96*single_sd)\n",
    "                lower_ci_p.append(single_ate-1.96*single_sd)\n",
    "\n",
    "            ate_hat = np.median(ate_p)\n",
    "            sd = np.median(sd_p)\n",
    "            upper_limit = np.mean(upper_ci_p)\n",
    "            lower_limit = np.mean(lower_ci_p)\n",
    "            CLD = upper_limit-lower_limit\n",
    "            s_df = pd.DataFrame([(ate_hat,sd,'('+str(lower_limit)+','+str(upper_limit)+')',CLD)],columns=['ATE','SD(ATE)','95% CL','CLD'])     \n",
    "\n",
    "            BIAS_lst = np.array(ate_p) - tate\n",
    "            t_BIAS = BIAS_lst.mean()#ate_hat - np.array(tate).mean()\n",
    "            ESE = np.std(BIAS_lst, ddof=1)\n",
    "            RMSE = np.sqrt(np.mean(BIAS_lst**2))\n",
    "            ASE = sd\n",
    "            Coverage = coverage(partition,lower_ci_p,upper_ci_p,tate)\n",
    "            e_df = pd.DataFrame([(t_BIAS,ESE,RMSE)],columns=['BIAS','ESE','RMSE'])     \n",
    "\n",
    "            if list(some_ate.keys()).index(indi)+sec_keys.index(sec_key)==0:\n",
    "                b_summary_df = s_df\n",
    "                b_evaluate_df = e_df\n",
    "            else:\n",
    "                b_summary_df = pd.concat([b_summary_df,s_df])\n",
    "                b_evaluate_df = pd.concat([b_evaluate_df,e_df])\n",
    "    b_summary_df['stats'] = flatten([[i]*len(sec_keys) for i in b_indicators])\n",
    "    b_summary_df['sec_stats'] = sec_keys*len(b_indicators)\n",
    "    b_evaluate_df['stats'] = flatten([[i]*len(sec_keys) for i in b_indicators])\n",
    "    b_evaluate_df['sec_stats'] = sec_keys*len(b_indicators)\n",
    "    b_p_summary_df = b_summary_df.groupby(['stats','sec_stats']).sum()\n",
    "    b_p_evaluate_df = b_evaluate_df.groupby(['stats','sec_stats']).sum()\n",
    "    return b_p_evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate eigenscores from image samples\n",
    "part = 100\n",
    "sample_num = 1500\n",
    "Za_image = []\n",
    "Zb_image = []\n",
    "img_arr = []\n",
    "eg_score = []\n",
    "for __ in range(part):\n",
    "    img_arr = []\n",
    "    image_beta_a = np.random.normal(0, 0.5, 1500)\n",
    "    image_beta_b = np.random.uniform(-1, 1, 1500)\n",
    "    for _ in range(sample_num*__,sample_num*(__+1)):\n",
    "        single_img = np.load('./triple-crossfitting/simu_img/'+str(_)+'.npy')\n",
    "        img_arr.append(single_img*50)\n",
    "    img_arr = np.array(img_arr)\n",
    "    eigenscores = get_est_U(X=img_arr,N=len(img_arr),return_eigenscore=True)\n",
    "    Za_image.append(np.dot(image_beta_a,eigenscores))\n",
    "    Zb_image.append(np.dot(image_beta_b,eigenscores))\n",
    "Za_image = np.array(Za_image).reshape(part*sample_num,)\n",
    "Zb_image = np.array(Zb_image).reshape(part*sample_num,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleNumber = 1500*100\n",
    "sigma1 = np.random.normal(0, 1, SampleNumber)\n",
    "Z1 = np.random.uniform(-1, 2, SampleNumber)\n",
    "Z2 = np.random.binomial(1, 0.7, SampleNumber)\n",
    "Z3 = np.random.binomial(1, 0.5, SampleNumber)\n",
    "Z4 = np.random.binomial(1, 0.3, SampleNumber)\n",
    "a = np.array([random.choice([12,14,16,16,18,20]) for _ in range(int(0.8*SampleNumber))])\n",
    "b = np.array([random.choice([13,15,17,19]) for _ in range(int(0.15*SampleNumber))])\n",
    "c = np.random.randint(4,12,SampleNumber-int(0.95*SampleNumber))\n",
    "Z5 = np.append(np.append(a,b),c)\n",
    "random.shuffle(Z5)\n",
    "\n",
    "d = np.random.normal(72.5, 2, int(0.5*SampleNumber))\n",
    "e = np.random.normal(77.5, 3, SampleNumber-int(0.5*SampleNumber))\n",
    "Z6 = np.append(d,e)\n",
    "random.shuffle(Z6)\n",
    "\n",
    "X = np.random.binomial(1,expit(-2+2*np.sin(Za_image)-(Z1)**3/5-Z2*(Z3+2)**2/5+Z5**2/125+((Z4+1)*Z6)/80))  \n",
    "Y = -1+4*X+2*np.cos(Zb_image)**2+(Z1**3)/2+((Z2)**2)+3*Z4*(Z3-3)**2+Z5**2/100+(np.log(Z6-Z5-30)) + sigma1\n",
    "\n",
    "simu_frame = pd.DataFrame(Y.reshape(SampleNumber,1),columns=['Y'])\n",
    "simu_frame['Treatment'] = X\n",
    "simu_frame['Z1'] = Z1\n",
    "simu_frame['Z2'] = Z2\n",
    "simu_frame['Z3'] = Z3\n",
    "simu_frame['Z4'] = Z4\n",
    "simu_frame['Z5'] = Z5\n",
    "simu_frame['Z6'] = Z6\n",
    "simu_frame['Za_image'] = np.sin(Za_image)\n",
    "simu_frame['Zb_image'] = np.cos(Zb_image)**2\n",
    "\n",
    "simu_frame['X_01'] = (Z1)**3\n",
    "simu_frame['X_02'] = (Z2)*(Z3+2)\n",
    "simu_frame['X_03'] = Z5**2/125\n",
    "simu_frame['X_04'] = ((Z4+1)*Z6)/80\n",
    "\n",
    "simu_frame['Y_01'] = (((Z1)**3))\n",
    "simu_frame['Y_02'] = (Z2)**2\n",
    "simu_frame['Y_03'] = Z4*(Z3-3)**2\n",
    "simu_frame['Y_04'] = Z5**2/100\n",
    "simu_frame['Y_05'] = (np.log(Z6-Z5-30)) \n",
    "\n",
    "all_simuframe = simu_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1500\n",
    "partition = range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Please see \"Simulation1-2.ipynb\" Notes for more details \n",
    "'''\n",
    "baseline_ate = {}\n",
    "baseline_time_lst = {}\n",
    "baseline_ate['G_Computation'] = {}\n",
    "baseline_ate['IPW'] = {}\n",
    "baseline_ate['DR'] = {}\n",
    "baseline_time_lst['G_Computation'] = {}\n",
    "baseline_time_lst['IPW'] = {}\n",
    "baseline_time_lst['DR'] = {}\n",
    "b_true_ate = []\n",
    "b_true_ate1 = []\n",
    "part1_time = 0\n",
    "ps_tm = {}\n",
    "rsp_tm = {}\n",
    "ev_keys = ['True','Main Effect','ML']\n",
    "for k in ev_keys:\n",
    "    baseline_ate['G_Computation'][k] = {}\n",
    "    baseline_ate['IPW'][k] = {}\n",
    "    baseline_ate['DR'][k] = {}\n",
    "    ps_tm[k] = 0\n",
    "    rsp_tm[k] = 0\n",
    "for __ in partition:\n",
    "    sys.stdout.write('\\r'+str(__+1)+'/100')\n",
    "    for k in ev_keys:\n",
    "        baseline_ate['G_Computation'][k][__] = []\n",
    "        baseline_ate['IPW'][k][__] = []\n",
    "        baseline_ate['DR'][k][__] = []  \n",
    "    # load data\n",
    "    simu_frame = all_simuframe.iloc[sample_size*__:sample_size*(__+1),:]\n",
    "    observers = []\n",
    "    for _img_ in range(1500*__,1500*(__+1)):\n",
    "        s_img = np.load('D:/数据/triple-crossfitting/ADNIGO2/simu_img/'+str(_img_)+'.npy')\n",
    "        observers.append(s_img)\n",
    "    observers = np.array(observers)\n",
    "    start = time.perf_counter()\n",
    "    eigenscores = get_est_U(X=observers,N=len(observers),return_eigenscore=True)\n",
    "    eigenframe = pd.DataFrame(eigenscores.T,index=simu_frame.index) \n",
    "    CPV_frame = ((eigenframe.var())/(eigenframe.var()).sum()).cumsum()\n",
    "    num_of_f = CPV_frame[CPV_frame>0.95].index[0]\n",
    "    eigenframe.columns = ['es'+str(i) for i in eigenframe.columns]\n",
    "    simu_frame_a = simu_frame.merge(eigenframe[['es'+str(i) for i in range(num_of_f)]],left_index=True,right_index=True)\n",
    "    eigen_formu = '+'.join([i for i in simu_frame_a.columns if 'es' in i])\n",
    "    t_simu_frame = simu_frame_a\n",
    "    t_simu_frame['par1'] = flatten([i]*int(len(t_simu_frame)/2) for i in range(2))\n",
    "    part1_time+= time.perf_counter()-start\n",
    "    for cv in range(2):\n",
    "        p2_time = time.perf_counter()\n",
    "        train_simu_frame = t_simu_frame[t_simu_frame['par1']==cv]   \n",
    "        test_simu_frame = t_simu_frame[t_simu_frame['par1']!=cv]  \n",
    "        train_simu_frame['idx'] = range(len(train_simu_frame.index))\n",
    "        train_simu_frame.set_index('idx',inplace=True)\n",
    "        test_simu_frame['idx'] = range(len(test_simu_frame.index))\n",
    "        test_simu_frame.set_index('idx',inplace=True)\n",
    "        \n",
    "        dr.data_loadin(train_simu_frame,test_simu_frame)\n",
    "        part1_time += time.perf_counter()-p2_time\n",
    "        for sec_keys in ev_keys:\n",
    "            if sec_keys=='True':\n",
    "                ps_formula = 'Treatment ~Za_image+ X_01 + X_02 + X_03+ X_04'\n",
    "                rsp_formula = 'Y~Zb_image+Treatment+ Y_01+Y_02+Y_03+Y_04+Y_05'\n",
    "            else:\n",
    "                ps_formula = 'Treatment ~ Z1 + Z2 + Z3 + Z4 + Z5 + Z6'\n",
    "                rsp_formula = 'Y ~ Treatment + Z1 + Z2 + Z3 + Z4 + Z5 + Z6'\n",
    "\n",
    "                ps_formula = ps_formula+'+'+eigen_formu\n",
    "                rsp_formula = rsp_formula+'+'+eigen_formu\n",
    "            if sec_keys=='ML':\n",
    "                ml_flag=True\n",
    "                test_simu_frame['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_method=True) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                test_simu_frame['u0_X'],test_simu_frame['u1_X'],rsp_t = dr.rsp_Model(rsp_formula,ml_method=True,model_type='continue')          \n",
    "                rsp_tm[sec_keys]+=rsp_t\n",
    "            else:\n",
    "                ml_flag=False\n",
    "                test_simu_frame['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_method=False) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                test_simu_frame['u0_X'],test_simu_frame['u1_X'],rsp_t = dr.rsp_Model(rsp_formula,ml_method=False,model_type='continue')     \n",
    "                rsp_tm[sec_keys]+=rsp_t\n",
    "            baseline_data = test_simu_frame[['Treatment','propensity_score','u1_X','u0_X','Y']] \n",
    "            baseline_data['Y_F'] = baseline_data['Y']\n",
    "            baseline_ate_pos = (baseline_data['Treatment']*(baseline_data['Y_F']-baseline_data['u1_X']))/baseline_data['propensity_score'] + baseline_data['u1_X']\n",
    "            baseline_ate_neg = ((1.0-baseline_data['Treatment'])*(baseline_data['Y_F']-baseline_data['u0_X']))/(1.0-baseline_data['propensity_score']) + baseline_data['u0_X']           \n",
    "\n",
    "            DR = baseline_ate_pos-baseline_ate_neg\n",
    "            G_Computation = baseline_data['u1_X'] - baseline_data['u0_X']\n",
    "            IPW = ((baseline_data['Treatment']*baseline_data['Y_F'])/baseline_data['propensity_score'])-(((1.0-baseline_data['Treatment'])*baseline_data['Y_F'])/(1.0-baseline_data['propensity_score']))\n",
    "\n",
    "            baseline_ate['G_Computation'][sec_keys][__].append(G_Computation)\n",
    "            baseline_ate['IPW'][sec_keys][__].append(IPW)\n",
    "            baseline_ate['DR'][sec_keys][__].append(DR)\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (('IPW-ML:')+str((part1_time+ps_tm['ML'])))\n",
    "print (('IPW-MAIN:')+str((part1_time+ps_tm['Main Effect'])))\n",
    "print (('IPW-TRUE:')+str((part1_time+ps_tm['True'])))\n",
    "print (('G-ML:')+str((part1_time+rsp_tm['ML'])))\n",
    "print (('G-MAIN:')+str((part1_time+rsp_tm['Main Effect'])))\n",
    "print (('G-TRUE:')+str((part1_time+rsp_tm['True'])))\n",
    "print (('DR-ML:')+str((part1_time+rsp_tm['ML']+ps_tm['ML'])))\n",
    "print (('DR-MAIN:')+str((part1_time+rsp_tm['Main Effect']+ps_tm['Main Effect'])))\n",
    "print (('DR-TRUE:')+str((part1_time+rsp_tm['True']+ps_tm['True'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = evaluate(baseline_ate,np.array([4]*len(partition)), 2)\n",
    "e_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_ate = {}\n",
    "dc_time_lst = {}\n",
    "part1_time = 0\n",
    "ps_tm = {}\n",
    "rsp_tm = {}\n",
    "dc_ate['DC_DR'] = {}\n",
    "dc_time_lst['DC_DR'] = {}\n",
    "splits = [1,2,3]\n",
    "simu_splits = []\n",
    "# ev_keys = ['True','Main Effect']\n",
    "for k in ev_keys:\n",
    "    dc_ate['DC_DR'][k] = {}\n",
    "    dc_time_lst['DC_DR'][k] = []\n",
    "for __ in partition:\n",
    "    simu_frame = all_simuframe.iloc[sample_size*__:sample_size*(__+1),:]\n",
    "    observers = []\n",
    "    for _img_ in range(1500*__,1500*(__+1)):\n",
    "        s_img = np.load('D:/数据/triple-crossfitting/ADNIGO2/simu_img/'+str(_img_)+'.npy')\n",
    "        observers.append(s_img)\n",
    "    observers = np.array(observers)\n",
    "    start = time.perf_counter()\n",
    "    eigenscores = get_est_U(X=observers,N=len(observers),return_eigenscore=True)\n",
    "    eigenframe = pd.DataFrame(eigenscores.T,index=simu_frame.index) \n",
    "    CPV_frame = ((eigenframe.var())/(eigenframe.var()).sum()).cumsum()\n",
    "    num_of_f = CPV_frame[CPV_frame>0.95].index[0]\n",
    "    eigenframe.columns = ['es'+str(i) for i in eigenframe.columns]\n",
    "    simu_frame_a = simu_frame.merge(eigenframe[['es'+str(i) for i in range(num_of_f)]],left_index=True,right_index=True)\n",
    "    eigen_formu = '+'.join([i for i in simu_frame_a.columns if 'es' in i])\n",
    "    t_simu_frame = simu_frame_a\n",
    "    \n",
    "    sys.stdout.write('\\r'+str(__+1)+'/100')\n",
    "    # cross-modeling\n",
    "    simu_frame1,simu_frame2,simu_frame3 = dc_sample_splitting(t_simu_frame)\n",
    "    \n",
    "    # hdfpca / psm-model / response\n",
    "    for o in splits:\n",
    "        eval('simu_frame'+str(o))['idx'] = range(len(eval('simu_frame'+str(o)).index))\n",
    "        eval('simu_frame'+str(o)).set_index('idx',inplace=True)\n",
    "    for kys in ev_keys:\n",
    "        dc_ate['DC_DR'][kys][__] = []\n",
    "        ps_tm[kys] = 0\n",
    "        rsp_tm[kys] = 0\n",
    "    combi_lst = (list(itertools.permutations(splits, 3)))\n",
    "    part1_time+=time.perf_counter()-start\n",
    "    for combi in combi_lst: #【2,3,4】         \n",
    "        simu_frame11 = simu_frame1.copy()\n",
    "        simu_frame12 = simu_frame2.copy()\n",
    "        simu_frame13 = simu_frame3.copy()\n",
    "        # propensity score        \n",
    "        for sec_keys in ev_keys:\n",
    "            if sec_keys=='True':\n",
    "                ps_formula = 'Treatment ~Za_image+ X_01 + X_02 + X_03+ X_04'\n",
    "                rsp_formula = 'Y~Zb_image+Treatment+ Y_01+Y_02+Y_03+Y_04+Y_05'\n",
    "            else:\n",
    "                ps_formula = 'Treatment ~ Z1 + Z2 + Z3 + Z4 + Z5 + Z6'\n",
    "                rsp_formula = 'Y ~ Treatment + Z1 + Z2 + Z3 + Z4 + Z5 + Z6'\n",
    "\n",
    "                ps_formula = ps_formula+'+'+eigen_formu\n",
    "                rsp_formula = rsp_formula+'+'+eigen_formu\n",
    "            if sec_keys=='ML':\n",
    "                ml_flag=True\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))\n",
    "                eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_flag) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                eval('simu_frame1'+str(combi[0]))['u0_X'],eval('simu_frame1'+str(combi[0]))['u1_X'],rsp_t = dr.rsp_Model(rsp_formula,ml_method=True,model_type='continue')          \n",
    "                rsp_tm[sec_keys]+=rsp_t\n",
    "            else:\n",
    "                ml_flag=False\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))\n",
    "                eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_method=False) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                eval('simu_frame1'+str(combi[0]))['u0_X'],eval('simu_frame1'+str(combi[0]))['u1_X'],rsp_t = dr.rsp_Model(rsp_formula,ml_method=False,model_type='continue')     \n",
    "                rsp_tm[sec_keys]+=rsp_t\n",
    "\n",
    "            data = eval('simu_frame1'+str(combi[0]))[['Treatment','propensity_score','u1_X','u0_X','Y']] \n",
    "            data['Y_F'] = data['Y']\n",
    "            ate_pos = (data['Treatment']*(data['Y_F']-data['u1_X']))/data['propensity_score'] + data['u1_X']\n",
    "            ate_neg = ((1.0-data['Treatment'])*(data['Y_F']-data['u0_X']))/(1.0-data['propensity_score']) + data['u0_X']           \n",
    "            DC_DR = ate_pos-ate_neg\n",
    "\n",
    "            dc_ate['DC_DR'][sec_keys][__].append(DC_DR)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ((ps_tm['ML']+rsp_tm['ML']+part1_time))\n",
    "print ((ps_tm['Main Effect']+rsp_tm['Main Effect']+part1_time))\n",
    "print ((ps_tm['True']+rsp_tm['True']+part1_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = evaluate(dc_ate,np.array([4]*len(partition)), 6)\n",
    "e_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# main simulation section\n",
    "splits = [1,2,3,4]\n",
    "part1_time = 0\n",
    "ps_tm = {}\n",
    "rsp_tm = {}\n",
    "partition_ate = {}\n",
    "partition_time_lst = {}\n",
    "partition_ate['TC_DR'] = {}\n",
    "partition_time_lst['TC_DR'] = {}\n",
    "for k in ev_keys:\n",
    "    partition_ate['TC_DR'][k] = {}\n",
    "    partition_time_lst['TC_DR'][k] = []\n",
    "for __ in partition:\n",
    "    sys.stdout.write('\\r'+str(__+1)+'/100')\n",
    "    # cross-modeling\n",
    "    simu_frame = all_simuframe.iloc[sample_size*__:sample_size*(__+1),:]\n",
    "    simu_frame['id'] = range(len(simu_frame.index))\n",
    "    simu_frame = simu_frame.set_index('id')\n",
    "    observers = []\n",
    "    for _img_ in range(1500):\n",
    "        s_img = np.load('./triple-crossfitting/simu_img/'+str(_img_)+'.npy')\n",
    "        observers.append(s_img)\n",
    "    observers = np.array(observers)\n",
    "    \n",
    "    true,simu_frame1,image_observer1,simu_frame2,image_observer2,simu_frame3,image_observer3,simu_frame4,image_observer4 = sample_splitting(simu_frame,observers,0,resample=False,sample_num=sample_size)  \n",
    "    # hdfpca / psm-model / response    \n",
    "    for o in splits:\n",
    "        eval('simu_frame'+str(o))['idx'] = range(len(simu_frame1.index))\n",
    "        eval('simu_frame'+str(o)).set_index('idx',inplace=True)\n",
    "    for kys in ev_keys:\n",
    "        partition_ate['TC_DR'][kys][__] = []\n",
    "        ps_tm[kys] = 0\n",
    "        rsp_tm[kys] = 0\n",
    "    for _ in splits:   \n",
    "        start = time.perf_counter()\n",
    "        est_u = get_est_U(X=eval('image_observer'+str(_)),N=len(image_observer1))\n",
    "        est_u_inv = est_u.T \n",
    "        sec_splits = splits.copy()\n",
    "        sec_splits.remove(_)\n",
    "        combi_lst = (list(itertools.permutations(sec_splits, 3)))       \n",
    "        \n",
    "        eigenframe1 = pd.DataFrame(np.matmul(est_u_inv,get_X_bar(X=image_observer1,N=len(image_observer1)).T).T)    \n",
    "        CPV_frame = ((eigenframe1.var())/((eigenframe1.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe1 = eigenframe1.reindex(CPV_frame.index)\n",
    "        CPV_frame1 = frame_reindex(CPV_frame)    \n",
    "        eigenframe1.columns = CPV_frame1.index\n",
    "        \n",
    "        eigenframe2 = pd.DataFrame(np.matmul(est_u_inv,get_X_bar(X=image_observer2,N=len(image_observer2)).T).T)  \n",
    "        CPV_frame = ((eigenframe2.var())/((eigenframe2.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe2 = eigenframe2.reindex(CPV_frame.index)\n",
    "        CPV_frame2 = frame_reindex(CPV_frame) \n",
    "        eigenframe2.columns = CPV_frame2.index\n",
    "\n",
    "        eigenframe3 = pd.DataFrame(np.matmul(est_u_inv,get_X_bar(X=image_observer3,N=len(image_observer3)).T).T)    \n",
    "        CPV_frame = ((eigenframe3.var())/((eigenframe3.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe3 = eigenframe3.reindex(CPV_frame.index)\n",
    "        CPV_frame3 = frame_reindex(CPV_frame) \n",
    "        eigenframe3.columns = CPV_frame3.index\n",
    "        \n",
    "        eigenframe4 = pd.DataFrame(np.matmul(est_u_inv,get_X_bar(X=image_observer4,N=len(image_observer4)).T).T) \n",
    "        CPV_frame = ((eigenframe4.var())/((eigenframe4.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe4 = eigenframe4.reindex(CPV_frame.index)\n",
    "        CPV_frame4 = frame_reindex(CPV_frame) \n",
    "        eigenframe4.columns = CPV_frame4.index\n",
    "        \n",
    "        \n",
    "        choose_index = eval('CPV_frame'+str(_))[eval('CPV_frame'+str(_))<0.95].index\n",
    "        simu_frame1[[i for i in choose_index]] = eigenframe1[[i for i in choose_index]]\n",
    "        simu_frame2[[i for i in choose_index]] = eigenframe2[[i for i in choose_index]]\n",
    "        simu_frame3[[i for i in choose_index]] = eigenframe3[[i for i in choose_index]]\n",
    "        simu_frame4[[i for i in choose_index]] = eigenframe4[[i for i in choose_index]]\n",
    "        part1_time+=time.perf_counter()-start\n",
    "        for combi in combi_lst: #【2,3,4】\n",
    "            simu_frame11 = simu_frame1.copy()\n",
    "            simu_frame12 = simu_frame2.copy()\n",
    "            simu_frame13 = simu_frame3.copy()\n",
    "            simu_frame14 = simu_frame4.copy()\n",
    "            for sec_keys in ev_keys:\n",
    "                if sec_keys=='True':\n",
    "                    ps_formula = 'Treatment ~Za_image+ X_01 + X_02 + X_03+ X_04'\n",
    "                    rsp_formula = 'Y~Zb_image+Treatment+ Y_01+Y_02+Y_03+Y_04+Y_05'\n",
    "                else:\n",
    "                    ps_formula = 'Treatment ~ Z1 + Z2 + Z3 + Z4 + Z5 + Z6'\n",
    "                    rsp_formula = 'Y ~ Treatment + Z1 + Z2 + Z3 + Z4 + Z5 + Z6'\n",
    "                ps_formula += '+'+'+'.join([i for i in simu_frame2.columns if 'es' in i])\n",
    "                rsp_formula += '+'+'+'.join([i for i in simu_frame2.columns if 'es' in i])\n",
    "                # propensity score\n",
    "                if sec_keys=='ML':\n",
    "                    ml_flag=True\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))\n",
    "                    eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_flag) \n",
    "                    ps_tm[sec_keys]+=ps_time\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                    eval('simu_frame1'+str(combi[0]))['u0_X'],eval('simu_frame1'+str(combi[0]))['u1_X'],rsp_t = dr.rsp_Model(rsp_formula,ml_method=True,model_type='continue')          \n",
    "                    rsp_tm[sec_keys]+=rsp_t\n",
    "                else:\n",
    "                    ml_flag=False\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))\n",
    "                    eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_method=False) \n",
    "                    ps_tm[sec_keys]+=ps_time\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                    eval('simu_frame1'+str(combi[0]))['u0_X'],eval('simu_frame1'+str(combi[0]))['u1_X'],rsp_t = dr.rsp_Model(rsp_formula,ml_method=False,model_type='continue')     \n",
    "                    rsp_tm[sec_keys]+=rsp_t\n",
    "                data = eval('simu_frame1'+str(combi[0]))[['Treatment','propensity_score','u1_X','u0_X','Y']] \n",
    "                data['Y_F'] = data['Y']\n",
    "                ate_pos = (data['Treatment']*(data['Y_F']-data['u1_X']))/data['propensity_score'] + data['u1_X']\n",
    "                ate_neg = ((1.0-data['Treatment'])*(data['Y_F']-data['u0_X']))/(1.0-data['propensity_score']) + data['u0_X']           \n",
    "\n",
    "                TC_DR = ate_pos-ate_neg\n",
    "                partition_ate['TC_DR'][sec_keys][__].append(TC_DR)\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ((ps_tm['ML']+rsp_tm['ML']+part1_time))\n",
    "print ((ps_tm['Main Effect']+rsp_tm['Main Effect']+part1_time))\n",
    "print ((ps_tm['True']+rsp_tm['True']+part1_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = evaluate(partition_ate,np.array([4]*len(partition)), 24)\n",
    "e_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
