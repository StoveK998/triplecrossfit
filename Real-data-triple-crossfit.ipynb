{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import statsmodels.formula.api as smf\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor,StackingRegressor\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from scipy.special import expit\n",
    "xgb.set_config(verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In real data analysis, we no longer need to generate sample image, \n",
    "    but only need to compute the eigenscores of the MRI image.\n",
    "'''\n",
    "from __future__ import division\n",
    "from scipy.optimize import fsolve, root\n",
    "from scipy import integrate\n",
    "from sympy import Symbol, exp, log\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.stats\n",
    "import numpy.random as nrd\n",
    "import multiprocessing\n",
    "\n",
    "def get_est_U(df,l=300):\n",
    "    df['idx'] = range(len(df))\n",
    "    df = df.set_index('idx')\n",
    "    N = len(df.index)\n",
    "    pg = 601\n",
    "    L = l\n",
    "    X_bar_part_lst = []\n",
    "    X_bar_square = np.zeros(shape=[N, N])\n",
    "    part_img = np.zeros(shape=[N,L,pg])\n",
    "    for i in range(N):\n",
    "        img_path = './triple-crossfitting/total_image_array/'+df['PTID'][i]+'-img_part.npy'\n",
    "        img = np.load(img_path)\n",
    "        part_img[i] = img\n",
    "    aa = part_img.reshape((N,-1))/601\n",
    "    aa = aa - np.mean(aa, 0)[np.newaxis] \n",
    "    bb = aa.reshape((N,L,pg))\n",
    "    for l in range(L):\n",
    "        X_bar_part = bb[:,l,:]\n",
    "        X_bar_square += np.matmul(X_bar_part, X_bar_part.transpose())\n",
    "        X_bar_part_lst.append(X_bar_part)\n",
    "    v, s_2, vt = la.svd(X_bar_square)  # u: n*n, s: n (eigenvalue)\n",
    "    est_eimg = np.zeros([N, L, pg])\n",
    "\n",
    "    for l in range(L):\n",
    "        X_bar_part = X_bar_part_lst[l]\n",
    "        est_eimg[:, l] = np.matmul(X_bar_part.T, np.matmul(v, np.sqrt(np.diag(1/s_2)))).T # U(m)=X(m)VS_-1\n",
    "    U = est_eimg.reshape((N, -1))\n",
    "    return U#est_eimg\n",
    "\n",
    "def get_eigenscore(df,est_u,ll=300):\n",
    "    N = len(df.index)\n",
    "    L = ll\n",
    "    grid = 601\n",
    "    part_img = np.zeros(shape=[N,L, grid])\n",
    "    for i in range(N):\n",
    "        img_path = './triple-crossfitting/total_image_array/'+df['PTID'][i]+'-img_part.npy'\n",
    "        img = np.load(img_path)\n",
    "        part_img[i] = img\n",
    "    aa = part_img.reshape((N,-1))/601\n",
    "    aa = aa - np.mean(aa, 0)[np.newaxis] \n",
    "    eigenscore = np.matmul(est_u,aa.T)\n",
    "    return eigenscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from pygam import GAM,LogisticGAM\n",
    "class DRModel():\n",
    "    def __init__(self):\n",
    "        self.binary_model_lst = None\n",
    "        self.continue_model_lst = None\n",
    "        self.train_df = None\n",
    "        self.test_df = None \n",
    "    def data_loadin(self,train_df,test_df):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df \n",
    "    def ml_models(self,binary_models,continue_models):\n",
    "        self.binary_model_lst = binary_models\n",
    "        self.continue_model_lst = continue_models\n",
    "        \n",
    "    def KFold_val(self,train=None,indep_var=None,dep_var=None,model=None,model_type = 'binary'):\n",
    "        X, Y = pd.DataFrame(train[indep_var]), pd.DataFrame(train[dep_var])\n",
    "        if model_type == 'binary':\n",
    "            scores = cross_val_score(model, X, Y, cv=3, scoring='accuracy')\n",
    "        elif model_type == 'continue':\n",
    "            scores = cross_val_score(model, X, Y, cv=3, scoring='neg_mean_squared_error')\n",
    "        return np.mean(scores)      \n",
    "    \n",
    "    def stacking(self,formula,train=None,test=None,return_proba=False,model_type = 'binary'):\n",
    "        indep_var = formula.split('~')[-1].replace(' ','').split('+')\n",
    "        dep_var = formula.split('~')[0].replace(' ','')\n",
    "        stacking_df = pd.DataFrame()\n",
    "        stacking_test_df = pd.DataFrame()\n",
    "        if model_type == 'binary':\n",
    "            model_lst = self.binary_model_lst\n",
    "        elif model_type == 'continue':\n",
    "            model_lst = self.continue_model_lst \n",
    "        for model in model_lst:\n",
    "            result = np.array([])\n",
    "            for train_idx,text_idx in KFold(n_splits=3).split(train):\n",
    "                model1 = model\n",
    "                X_train, X_test = train.loc[train_idx,indep_var], train.loc[text_idx,indep_var]\n",
    "                y_train, y_test = train.loc[train_idx,dep_var], train.loc[text_idx,dep_var]\n",
    "                result = np.append(result,model1.fit(X_train,y_train).predict(X_test))\n",
    "            stacking_df[str(model).split('(')[0]] = result\n",
    "            model.fit(train[indep_var],train[dep_var])\n",
    "            stacking_test_df[str(model).split('(')[0]] = model.predict(test[indep_var])\n",
    "        stacking_df['label'] = train[dep_var]\n",
    "        \n",
    "        if model_type == 'binary':\n",
    "            meta_model = LogisticRegression()\n",
    "            meta_model.fit(stacking_df[stacking_df.columns[:-1]],stacking_df['label'])\n",
    "            if return_proba==True:\n",
    "                res = meta_model.predict_proba(stacking_test_df)[:,1]\n",
    "            else:\n",
    "                res = meta_model.predict(stacking_test_df)\n",
    "        elif model_type == 'continue':\n",
    "            meta_model = LinearRegression()\n",
    "            meta_model.fit(stacking_df[stacking_df.columns[:-1]],stacking_df['label'])\n",
    "            res = meta_model.predict(stacking_test_df)\n",
    "        return res\n",
    "            \n",
    "        \n",
    "    def ps_Model(self,formula,ml_method=False,model_type='binary'):\n",
    "        indep_var = formula.split('~')[-1].replace(' ','').split('+')\n",
    "        treatment_var = formula.split('~')[0].replace(' ','')\n",
    "        # calculate propensity score\n",
    "        start = time.perf_counter()\n",
    "        if ml_method==True:\n",
    "            if model_type=='binary':\n",
    "                mods = self.binary_model_lst.copy()[1:]\n",
    "            elif model_type == 'continue':\n",
    "                mods = self.continue_model_lst.copy()[1:]\n",
    "            ml_val_lst = []\n",
    "            for model1 in mods:\n",
    "                ml_val_lst.append(dr.KFold_val(self.train_df,indep_var,treatment_var,model1))\n",
    "            model = mods[np.argmax(ml_val_lst)]\n",
    "            model.fit(self.train_df[indep_var],self.train_df[treatment_var])\n",
    "            try:\n",
    "                try:\n",
    "                    propensity_score = model.predict_proba(self.test_df[indep_var])[:,1]\n",
    "                except:\n",
    "                    propensity_score = model.predict_proba(self.test_df[indep_var])\n",
    "            except:\n",
    "                propensity_score = model.predict(self.test_df[indep_var])[:,1]\n",
    "            propensity_score = np.where(propensity_score<0.005,0.005,propensity_score)\n",
    "            propensity_score = np.where(propensity_score>0.995,0.995,propensity_score)\n",
    "        else:\n",
    "            if model_type=='binary':\n",
    "                model = LogisticRegression()\n",
    "            elif model_type == 'continue':\n",
    "                model = LinearRegression()\n",
    "            model.fit(self.train_df[indep_var],self.train_df[treatment_var])\n",
    "            propensity_score = model.predict_proba(self.test_df[indep_var])[:,1]\n",
    "        return propensity_score,time.perf_counter()-start \n",
    "            \n",
    "    def rsp_Model(self,formula,label,ml_method=False,model_type='binary'):\n",
    "        indep_var = formula.split('~')[-1].replace(' ','').split('+')\n",
    "        response_var = formula.split('~')[0].replace(' ','')\n",
    "        value_y = label\n",
    "        train = self.train_df[self.train_df['APOE4']==int(value_y)]\n",
    "        train.reset_index(drop=True,inplace=True)\n",
    "        start = time.perf_counter()\n",
    "        if ml_method==True:\n",
    "            if model_type=='binary':\n",
    "                mods = self.binary_model_lst.copy()[1:]\n",
    "                stacking_model = StackingClassifier(self.binary_model_lst[1:],LG_psmodel)\n",
    "            elif model_type == 'continue':\n",
    "                mods = self.continue_model_lst.copy()[1:]\n",
    "                stacking_model = StackingRegressor(self.continue_model_lst[1:],Linear_rspmodel)            \n",
    "            mods.append(stacking_model)\n",
    "            ml_val_lst = []\n",
    "            for model1 in mods:\n",
    "                ml_val_lst.append(dr.KFold_val(train,indep_var,response_var,model1,model_type=model_type))\n",
    "            model = mods[np.argmax(ml_val_lst)]\n",
    "        else:\n",
    "            if model_type=='binary':\n",
    "                model = LogisticRegression()\n",
    "            elif model_type == 'continue':\n",
    "                model = LinearRegression()\n",
    "        model.fit(train[indep_var],train[response_var])\n",
    "        ui_x = model.predict(self.test_df[indep_var])       \n",
    "        return ui_x,time.perf_counter()-start \n",
    "    \n",
    "    \n",
    "LG_psmodel = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "Linear_rspmodel = LinearRegression()\n",
    "\n",
    "RF_psmodel = RandomForestClassifier()\n",
    "RF_rspmodel = RandomForestRegressor()\n",
    "\n",
    "ADA_rspmodel = AdaBoostRegressor(learning_rate=0.05)\n",
    "ADA_psmodel = AdaBoostClassifier()\n",
    "\n",
    "XGB_rspmodel = xgb.XGBRegressor(n_estimators=500,learning_rate=0.005)\n",
    "XGB_psmodel = xgb.XGBClassifier(n_estimators=500,learning_rate=0.005)\n",
    "\n",
    "GAM_rspmodel = GAM(link='identity',n_splines=4,lam=0.6,max_iter=10000)\n",
    "GAM_psmodel =  LogisticGAM(n_splines=4,lam=0.6,max_iter=10000)\n",
    "\n",
    "BPNN_rspmodel = MLPRegressor(hidden_layer_sizes=(128,),activation='relu',max_iter=100,solver='lbfgs')\n",
    "BPNN_psmodel = MLPClassifier(hidden_layer_sizes=(128,),activation='relu',max_iter=100,solver='lbfgs')\n",
    "\n",
    "ps_mds = [LG_psmodel,RF_psmodel,ADA_psmodel,XGB_psmodel,BPNN_psmodel]\n",
    "rsp_mds = [Linear_rspmodel,RF_rspmodel,ADA_rspmodel,GAM_rspmodel]\n",
    "\n",
    "dr = DRModel()\n",
    "dr.ml_models(binary_models=ps_mds,continue_models=rsp_mds)\n",
    "ev_keys = ['ML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other functions\n",
    "def flatten(lis):\n",
    "    ret=[]\n",
    "    for item in lis:\n",
    "        if not isinstance(item,list):\n",
    "            ret.append(item)\n",
    "        else:\n",
    "            ret.extend(flatten(item))\n",
    "    return ret\n",
    "def coverage(p,lower,upper,true_value):\n",
    "    pp=len(p)\n",
    "    count = 0.0\n",
    "    for _ in range(pp):\n",
    "        if true_value[_] >= lower[_] and true_value[_] <= upper[_]:\n",
    "            count+=1.0\n",
    "    return count/pp\n",
    "\n",
    "def I(val_lst,min_thred=-100000,max_thred=100000):\n",
    "    kk = []\n",
    "    for val in val_lst:\n",
    "        if val>=min_thred and val<=max_thred:\n",
    "            kk.append(1)\n",
    "        else:\n",
    "            kk.append(0)\n",
    "    return np.array(kk)\n",
    "\n",
    "def frame_reindex(frame):\n",
    "    a = pd.DataFrame(frame,columns = ['egs'])\n",
    "    a['idx'] = ['es'+str(i) for i in range(len(a))]\n",
    "    a = a.set_index('idx')\n",
    "    return pd.Series(a['egs'])\n",
    "def sample_splitting(dataframe,resample=False):\n",
    "    simu_frame_s = dataframe    \n",
    "    frame_length = len(simu_frame_s.index)\n",
    "    \n",
    "    simu_frame1 = simu_frame_s.iloc[:int(frame_length*0.25),:]\n",
    "    image_observer1 = simu_frame1['PTID']\n",
    "    \n",
    "    simu_frame2 = simu_frame_s.iloc[int(frame_length*0.25):int(frame_length*0.5),:]\n",
    "    image_observer2 = simu_frame2['PTID']\n",
    "    \n",
    "    simu_frame3 = simu_frame_s.iloc[int(frame_length*0.5):int(frame_length*0.75),:]\n",
    "    image_observer3 = simu_frame3['PTID']\n",
    "    \n",
    "    simu_frame4 = simu_frame_s.iloc[int(frame_length*0.75):,:]\n",
    "    image_observer4 = simu_frame4['PTID']\n",
    "    \n",
    "    return simu_frame1,image_observer1,simu_frame2,image_observer2,simu_frame3,image_observer3,simu_frame4,image_observer4   \n",
    "\n",
    "\n",
    "def dc_sample_splitting(simu_frame_s):\n",
    "    frame_length = len(simu_frame_s.index)\n",
    "    simu_frame1 = simu_frame_s.iloc[:int(frame_length*0.333333),:]\n",
    "    simu_frame2 = simu_frame_s.iloc[int(frame_length*0.333333):int(frame_length*0.666666),:]\n",
    "    simu_frame3 = simu_frame_s.iloc[int(frame_length*0.666666):,:]\n",
    "    \n",
    "    return simu_frame1,simu_frame2,simu_frame3      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadin the processed data without eigenscores\n",
    "df = pd.read_csv('./triple-crossfitting/processed_df.csv')\n",
    "df = df.drop('idx',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate eigenscores with all data for use in computing \"baseline DR\" and \"DC-DR\"\n",
    "est_u = get_est_U(df,l=300)\n",
    "eigenframe = pd.DataFrame(get_eigenscore(df,est_u,ll=300))\n",
    "CPV_frame = ((eigenframe.var())/((eigenframe.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "eigenframe = eigenframe.T.reindex(CPV_frame.index).T\n",
    "CPV_frame = frame_reindex(CPV_frame)\n",
    "eigenframe.columns = CPV_frame.index\n",
    "choose_index = CPV_frame[CPV_frame<0.95].index\n",
    "t_simu_frame = df.merge(eigenframe[[i for i in choose_index]],left_index=True,right_index=True)\n",
    "t_simu_frame.to_csv('./triple-crossfitting/t_simu_frame.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadin the processed data with eigenscores\n",
    "t_simu_frame = pd.read_csv('./triple-crossfitting/t_simu_frame.csv')\n",
    "colu = t_simu_frame1.columns[1:]\n",
    "general_formu = colu.drop(['ADAS11', 'ADAS13', 'MMSE','APOE4'])\n",
    "dep_indicator = 'ADAS13' #ADAS11 MMSE\n",
    "ps_formula = 'APOE4 ~ '+'+'.join(list(general_formu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate baseline ATE using machine learning method\n",
    "baseline_ate = {}\n",
    "baseline_time_lst = {}\n",
    "baseline_ate['G_Computation'] = {}\n",
    "baseline_ate['IPW'] = {}\n",
    "baseline_ate['DR'] = {}\n",
    "baseline_time_lst['G_Computation'] = {}\n",
    "baseline_time_lst['IPW'] = {}\n",
    "baseline_time_lst['DR'] = {}\n",
    "true_ate = []\n",
    "part1_time = 0\n",
    "ps_tm = {}\n",
    "rsp_tm = {}\n",
    "ev_keys = ['ML']\n",
    "for k in ev_keys:\n",
    "    baseline_ate['G_Computation'][k] = {}\n",
    "    baseline_ate['IPW'][k] = {}\n",
    "    baseline_ate['DR'][k] = {}\n",
    "    ps_tm[k] = 0\n",
    "    rsp_tm[k] = 0\n",
    "for __ in partition:\n",
    "    for k in ev_keys:\n",
    "        baseline_ate['G_Computation'][k][__] = []\n",
    "        baseline_ate['IPW'][k][__] = []\n",
    "        baseline_ate['DR'][k][__] = []  \n",
    "    t_simu_frame = t_simu_frame1.sample(frac=1)\n",
    "    t_simu_frame = t_simu_frame1.iloc[:1350,:]\n",
    "    t_simu_frame['idx'] = range(len(t_simu_frame))\n",
    "    t_simu_frame = t_simu_frame.set_index('idx')\n",
    "    frame_length = len(t_simu_frame)\n",
    "    t_simu_frame['par'] = flatten([i]*675 for i in range(2))\n",
    "    for cv in range(2):\n",
    "        train_simu_frame = t_simu_frame[t_simu_frame['par']!=cv]   \n",
    "        test_simu_frame = t_simu_frame[t_simu_frame['par']==cv]      \n",
    "\n",
    "        train_simu_frame['idx'] = range(len(train_simu_frame.index))\n",
    "        train_simu_frame.set_index('idx',inplace=True)\n",
    "        test_simu_frame['idx'] = range(len(test_simu_frame.index))\n",
    "        test_simu_frame.set_index('idx',inplace=True)\n",
    "\n",
    "        dr.data_loadin(train_simu_frame,test_simu_frame)\n",
    "        ps_formula = 'APOE4 ~ '+'+'.join(list(general_formu))\n",
    "        rsp_formula = [dep_indicator, '~ '+'+'.join(list(general_formu)),\n",
    "                       '~ '+'+'.join(list(general_formu))]\n",
    "        for sec_keys in ev_keys:\n",
    "            if sec_keys=='ML':\n",
    "                ml_flag=True\n",
    "                test_simu_frame['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_method=ml_flag) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                rsp_formu = rsp_formula[0]+rsp_formula[1]\n",
    "                test_simu_frame['u0_X'],rsp_t = dr.rsp_Model(rsp_formu,0,ml_method=ml_flag,model_type='continue')     \n",
    "                rsp_formu = rsp_formula[0]+rsp_formula[2]\n",
    "                test_simu_frame['u1_X'],rsp_t = dr.rsp_Model(rsp_formu,1,ml_method=ml_flag,model_type='continue')     \n",
    "                rsp_tm[sec_keys]+=rsp_t\n",
    "            else:\n",
    "                ml_flag=False\n",
    "                test_simu_frame['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_method=ml_flag) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                response_time = 0\n",
    "                for label in [0,1]:\n",
    "                    rsp_formu = rsp_formula[0]+rsp_formula[label+1]\n",
    "                    test_simu_frame['u'+str(label)+'_X'],rsp_t = dr.rsp_Model(rsp_formu,label,ml_method=False,model_type='continue')     \n",
    "                    rsp_tm[sec_keys]+=rsp_t\n",
    "            baseline_data = test_simu_frame[['APOE4','propensity_score','u1_X','u0_X']] \n",
    "            baseline_data['Y_F'] = test_simu_frame[dep_indicator]\n",
    "            baseline_ate_pos = (baseline_data['APOE4']*(baseline_data['Y_F']-baseline_data['u1_X']))/baseline_data['propensity_score'] + baseline_data['u1_X']\n",
    "            baseline_ate_neg = ((1.0-baseline_data['APOE4'])*(baseline_data['Y_F']-baseline_data['u0_X']))/(1.0-baseline_data['propensity_score']) + baseline_data['u0_X']           \n",
    "            true_ate.append(baseline_data[baseline_data['APOE4']==1]['Y_F'].mean()-baseline_data[baseline_data['APOE4']==0]['Y_F'].mean())\n",
    "\n",
    "            DR = baseline_ate_pos-baseline_ate_neg\n",
    "            G_Computation = baseline_data['u1_X'] - baseline_data['u0_X']\n",
    "            IPW = ((baseline_data['APOE4']*baseline_data['Y_F'])/baseline_data['propensity_score'])-(((1.0-baseline_data['APOE4'])*baseline_data['Y_F'])/(1.0-baseline_data['propensity_score']))\n",
    "\n",
    "            baseline_ate['G_Computation'][sec_keys][__].append(G_Computation)\n",
    "            baseline_ate['IPW'][sec_keys][__].append(IPW)\n",
    "            baseline_ate['DR'][sec_keys][__].append(DR)\n",
    "np.save('./triple-crossfitting/true/ADAS13baseline_ate.npy',baseline_ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data Run-time\n",
    "print (('IPW-ML:')+str((part1_time+ps_tm['ML'])))\n",
    "print (('G-ML:')+str((part1_time+rsp_tm['ML'])))\n",
    "print (('DR-ML:')+str((part1_time+rsp_tm['ML']+ps_tm['ML'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DC-DR using machine learning method\n",
    "dc_ate = {}\n",
    "dc_time_lst = {}\n",
    "dc_ate['DC_DR'] = {}\n",
    "dc_time_lst['DC_DR'] = {}\n",
    "splits = [1,2,3]\n",
    "part1_time = 0\n",
    "ps_tm = {}\n",
    "rsp_tm = {}\n",
    "ev_keys = ['ML']\n",
    "true_ate = []\n",
    "for k in ev_keys:\n",
    "    dc_ate['DC_DR'][k] = {}\n",
    "    dc_time_lst['DC_DR'][k] = []\n",
    "\n",
    "ps_formula = 'APOE4 ~ '+'+'.join(list(general_formu))\n",
    "rsp_formula = [dep_indicator, '~ '+'+'.join(list(general_formu)),\n",
    "               '~ '+'+'.join(list(general_formu))]\n",
    "for __ in partition:\n",
    "    t_simu_frame = t_simu_frame1.sample(frac=1)\n",
    "    t_simu_frame = t_simu_frame.iloc[:1350,:] # to ensure the frame can be divided into three equal splits\n",
    "    start = time.perf_counter()\n",
    "    t_simu_frame['idx'] = range(len(t_simu_frame))\n",
    "    t_simu_frame = t_simu_frame.set_index('idx')\n",
    "    sys.stdout.write('\\r'+str(__+1)+'/100')\n",
    "    # cross-modeling\n",
    "    simu_frame1,simu_frame2,simu_frame3 = dc_sample_splitting(t_simu_frame)\n",
    "    # hdfpca / psm-model / response\n",
    "    for o in splits:\n",
    "        eval('simu_frame'+str(o))['idx'] = range(len(eval('simu_frame'+str(o)).index))\n",
    "        eval('simu_frame'+str(o)).set_index('idx',inplace=True)\n",
    "    for kys in ev_keys:\n",
    "        dc_ate['DC_DR'][kys][__] = []\n",
    "        ps_tm[kys] = 0\n",
    "        rsp_tm[kys] = 0\n",
    "    combi_lst = (list(itertools.permutations(splits, 3)))\n",
    "\n",
    "    for combi in combi_lst: #【2,3,4】\n",
    "        simu_frame11 = simu_frame1.copy()\n",
    "        simu_frame12 = simu_frame2.copy()\n",
    "        simu_frame13 = simu_frame3.copy()\n",
    "        part1_time+=time.perf_counter()-start\n",
    "        # propensity score        \n",
    "        for sec_keys in ev_keys:    \n",
    "            if sec_keys=='ML':\n",
    "                ml_flag=True\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))  \n",
    "                eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_flag) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                rsp_formu = rsp_formula[0]+rsp_formula[1]\n",
    "                eval('simu_frame1'+str(combi[0]))['u0_X'],rsp_t = dr.rsp_Model(rsp_formu,0,ml_flag,model_type='continue')   \n",
    "                rsp_tm[sec_keys]+=rsp_t\n",
    "                rsp_formu = rsp_formula[0]+rsp_formula[2]\n",
    "                eval('simu_frame1'+str(combi[0]))['u1_X'],rsp_t = dr.rsp_Model(rsp_formu,1,ml_flag,model_type='continue')   \n",
    "                rsp_tm[sec_keys]+=rsp_t\n",
    "            else:\n",
    "                ml_flag=False\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))\n",
    "                eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_flag) \n",
    "                ps_tm[sec_keys]+=ps_time\n",
    "                dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                for label in [0,1]:\n",
    "                    rsp_formu = rsp_formula[0]+rsp_formula[label+1]\n",
    "                    eval('simu_frame1'+str(combi[0]))['u'+str(label)+'_X'],response_time = dr.rsp_Model(rsp_formu,label,ml_flag,model_type='continue')   \n",
    "                    rsp_tm[sec_keys]+=rsp_t\n",
    "\n",
    "            data = eval('simu_frame1'+str(combi[0]))[['APOE4','propensity_score','u1_X','u0_X']] \n",
    "            data['Y_F'] = eval('simu_frame1'+str(combi[0]))[dep_indicator]\n",
    "            ate_pos = (data['APOE4']*(data['Y_F']-data['u1_X']))/data['propensity_score'] + data['u1_X']\n",
    "            ate_neg = ((1.0-data['APOE4'])*(data['Y_F']-data['u0_X']))/(1.0-data['propensity_score']) + data['u0_X']           \n",
    "            DC_DR = ate_pos-ate_neg\n",
    "            true_ate.append(data[data['APOE4']==1]['Y_F'].mean()-data[data['APOE4']==0]['Y_F'].mean())\n",
    "\n",
    "            dc_ate['DC_DR'][sec_keys][__].append(DC_DR)\n",
    "    sys.stdout.flush()\n",
    "np.save('./triple-crossfitting/true/ADAS13dc_ate.npy',dc_ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-time\n",
    "str((part1_time+rsp_tm['ML']+ps_tm['ML']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate TC-DR using machine learning method\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# main simulation section\n",
    "splits = [1,2,3,4]\n",
    "true_ate = []\n",
    "part1_time = 0\n",
    "ps_tm = {}\n",
    "rsp_tm = {}\n",
    "partition_ate = {}\n",
    "partition_time_lst = {}\n",
    "partition_ate['TC_DR'] = {}\n",
    "partition_time_lst['TC_DR'] = {}\n",
    "for k in ev_keys:\n",
    "    partition_ate['TC_DR'][k] = {}\n",
    "    partition_time_lst['TC_DR'][k] = []\n",
    "for __ in partition:\n",
    "    sys.stdout.write('\\r'+str(__+1)+'/100')\n",
    "    # cross-modeling\n",
    "    p_simu_frame = df.sample(frac=1)\n",
    "    p_simu_frame = p_simu_frame.iloc[:1348,:] # to ensure the frame can be divided into four equal splits\n",
    "    p_simu_frame = p_simu_frame.fillna(method='ffill')\n",
    "    p_simu_frame['idx'] = range(len(p_simu_frame))\n",
    "    p_simu_frame = p_simu_frame.set_index('idx')\n",
    "    simu_frame1,image_observer1,simu_frame2,image_observer2,simu_frame3,image_observer3,simu_frame4,image_observer4 = sample_splitting(p_simu_frame,resample=False)\n",
    "    # hdfpca / psm-model / response    \n",
    "    for o in splits:\n",
    "        eval('simu_frame'+str(o))['idx'] = range(len(simu_frame1.index))\n",
    "        eval('simu_frame'+str(o)).set_index('idx',inplace=True)\n",
    "    for kys in ev_keys:\n",
    "        partition_ate['TC_DR'][kys][__] = []\n",
    "        ps_tm[kys] = 0\n",
    "        rsp_tm[kys] = 0\n",
    "    for _ in splits: \n",
    "        start = time.perf_counter()\n",
    "        # calculate U ( X = USV(-1))\n",
    "        est_u = get_est_U(eval('simu_frame'+str(_)),l=300)\n",
    "        sec_splits = splits.copy()\n",
    "        sec_splits.remove(_)\n",
    "        combi_lst = (list(itertools.permutations(sec_splits, 3)))\n",
    "        \n",
    "        eigenframe1 = pd.DataFrame(get_eigenscore(simu_frame1,est_u,ll=300)).T  \n",
    "        CPV_frame = ((eigenframe1.var())/((eigenframe1.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe1 = eigenframe1.T.reindex(CPV_frame.index).T\n",
    "        CPV_frame1 = frame_reindex(CPV_frame)    \n",
    "        eigenframe1.columns = CPV_frame1.index\n",
    "\n",
    "        eigenframe2 = pd.DataFrame(get_eigenscore(simu_frame2,est_u,ll=300)).T  \n",
    "        CPV_frame = ((eigenframe2.var())/((eigenframe2.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe2 = eigenframe2.T.reindex(CPV_frame.index).T\n",
    "        CPV_frame2 = frame_reindex(CPV_frame) \n",
    "        eigenframe2.columns = CPV_frame2.index\n",
    "\n",
    "        eigenframe3 = pd.DataFrame(get_eigenscore(simu_frame3,est_u,ll=300)).T\n",
    "        CPV_frame = ((eigenframe3.var())/((eigenframe3.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe3 = eigenframe3.T.reindex(CPV_frame.index).T\n",
    "        CPV_frame3 = frame_reindex(CPV_frame) \n",
    "        eigenframe3.columns = CPV_frame3.index\n",
    "        \n",
    "        eigenframe4 = pd.DataFrame(get_eigenscore(simu_frame4,est_u,ll=300)).T\n",
    "        CPV_frame = ((eigenframe4.var())/((eigenframe4.var()).sum())).sort_values(ascending = False).cumsum()\n",
    "        eigenframe4 = eigenframe4.T.reindex(CPV_frame.index).T\n",
    "        CPV_frame4 = frame_reindex(CPV_frame) \n",
    "        eigenframe4.columns = CPV_frame4.index\n",
    "        \n",
    "        \n",
    "        choose_index = eval('CPV_frame'+str(_))[eval('CPV_frame'+str(_))<0.95].index\n",
    "        simu_frame1[[i for i in choose_index]] = eigenframe1[[i for i in choose_index]]\n",
    "        simu_frame2[[i for i in choose_index]] = eigenframe2[[i for i in choose_index]]\n",
    "        simu_frame3[[i for i in choose_index]] = eigenframe3[[i for i in choose_index]]\n",
    "        simu_frame4[[i for i in choose_index]] = eigenframe4[[i for i in choose_index]]\n",
    "        \n",
    "        cc = eval('simu_frame'+str(_)).columns[1:]\n",
    "        general_formu = cc.drop(['ADAS11', 'ADAS13', 'MMSE','APOE4'])\n",
    "        try:\n",
    "            general_formu = general_formu.drop('idx')\n",
    "        except:\n",
    "            pass\n",
    "        dep_indicator = 'ADAS13'\n",
    "        ps_formula = 'APOE4 ~ '+'+'.join(list(general_formu))\n",
    "        rsp_formula = [dep_indicator, '~ '+'+'.join(list(general_formu)),\n",
    "                       '~ '+'+'.join(list(general_formu))]\n",
    "        \n",
    "        part1_time+=time.perf_counter()-start\n",
    "        print (time.perf_counter()-start)\n",
    "        for combi in combi_lst: #【2,3,4】\n",
    "            simu_frame11 = simu_frame1.copy()\n",
    "            simu_frame12 = simu_frame2.copy()\n",
    "            simu_frame13 = simu_frame3.copy()\n",
    "            simu_frame14 = simu_frame4.copy()\n",
    "            for sec_keys in ev_keys:\n",
    "                if sec_keys=='ML':\n",
    "                    ml_flag=True\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))  \n",
    "                    eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_flag) \n",
    "                    ps_tm[sec_keys]+=ps_time\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                    rsp_formu = rsp_formula[0]+rsp_formula[1]\n",
    "                    eval('simu_frame1'+str(combi[0]))['u0_X'],rsp_t = dr.rsp_Model(rsp_formu,0,ml_flag,model_type='continue')   \n",
    "                    rsp_tm[sec_keys]+=rsp_t\n",
    "                    rsp_formu = rsp_formula[0]+rsp_formula[2]\n",
    "                    eval('simu_frame1'+str(combi[0]))['u1_X'],rsp_t = dr.rsp_Model(rsp_formu,1,ml_flag,model_type='continue')   \n",
    "                    rsp_tm[sec_keys]+=rsp_t\n",
    "                else:\n",
    "                    ml_flag=False\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[1])),eval('simu_frame1'+str(combi[0])))\n",
    "                    eval('simu_frame1'+str(combi[0]))['propensity_score'],ps_time = dr.ps_Model(ps_formula,ml_flag) \n",
    "                    ps_tm[sec_keys]+=ps_time\n",
    "                    dr.data_loadin(eval('simu_frame1'+str(combi[2])),eval('simu_frame1'+str(combi[0])))\n",
    "                    for label in [0,1]:\n",
    "                        rsp_formu = rsp_formula[0]+rsp_formula[label+1]\n",
    "                        eval('simu_frame1'+str(combi[0]))['u'+str(label)+'_X'],rsp_t = dr.rsp_Model(rsp_formu,label,ml_flag,model_type='continue')   \n",
    "                        rsp_tm[sec_keys]+=rsp_t\n",
    "                    \n",
    "                partition_time_lst['TC_DR'][sec_keys].append(response_time+ps_time)\n",
    "\n",
    "                data = eval('simu_frame1'+str(combi[0]))[['APOE4','propensity_score','u1_X','u0_X']] \n",
    "                data['Y_F'] = eval('simu_frame1'+str(combi[0]))[dep_indicator]\n",
    "                ate_pos = (data['APOE4']*(data['Y_F']-data['u1_X']))/data['propensity_score'] + data['u1_X']\n",
    "                ate_neg = ((1.0-data['APOE4'])*(data['Y_F']-data['u0_X']))/(1.0-data['propensity_score']) + data['u0_X']           \n",
    "                true_ate.append(data[data['APOE4']==1]['Y_F'].mean()-data[data['APOE4']==0]['Y_F'].mean())\n",
    "\n",
    "                TC_DR = ate_pos-ate_neg\n",
    "                partition_ate['TC_DR'][sec_keys][__].append(TC_DR)\n",
    "\n",
    "    sys.stdout.flush()\n",
    "np.save('./triple-crossfitting/true/ADAS13tc_ate.npy',partition_ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we got a nan value in computing the mean ATE, we can use the code below.\n",
    "TC_without_nan_value = []\n",
    "for i in partition:\n",
    "    mean_partition = []\n",
    "    for j in range(24):\n",
    "        if np.isnan(partition_ate['TC_AIPW']['ML'][i][j].mean()) == False:\n",
    "            mean_partition.append(partition_ate['TC_AIPW']['ML'][i][j].mean())\n",
    "    TC_without_nan_value.append(np.median(mean_partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the estimated ATE and its SD.\n",
    "zb = 'MMSE'\n",
    "indi = 'G_Computation'\n",
    "sec_key = 'ML'\n",
    "ttate = []\n",
    "load_file = './triple-crossfitting/true/MMSEbaseline_ate.npy'\n",
    "partition_ate = np.load(load_file,allow_pickle=True).item()\n",
    "ate_p = []\n",
    "for i in list(partition_ate[indi][sec_key].keys()):\n",
    "    sps_p = []\n",
    "    a_ate = flatten([list(i_.values) for i_ in partition_ate[indi][sec_key][i]])\n",
    "    par_ate = np.mean([i for i in a_ate if np.isnan(i)==False])\n",
    "    for j in range(2):\n",
    "        a_sp_p = list(partition_ate['G_Computation']['ML'][i][j].values)\n",
    "        sp_p = np.array([i for i in a_sp_p if np.isnan(i)==False])\n",
    "        sps_p.append(np.mean(sp_p))\n",
    "    single_ate = np.mean(sps_p)\n",
    "    ate_p.append(single_ate)\n",
    "ttate.append(ate_p)\n",
    "ttate = flatten(ttate)\n",
    "print (np.median(ttate))\n",
    "print (np.sqrt(np.median((ttate - np.mean(ttate))**2 + np.var(ttate))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
